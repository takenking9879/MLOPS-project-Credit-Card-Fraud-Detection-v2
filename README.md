<div align="center">

# üõ°Ô∏è MLOPS-project-Credit-Card-Fraud-Detection-v2

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)](https://www.python.org/)  
[![Airflow](https://img.shields.io/badge/Airflow-3.x-yellow?logo=apache-airflow)](https://airflow.apache.org/)  
[![Spark](https://img.shields.io/badge/Spark-4.0.1-orange?logo=apache-spark)](https://spark.apache.org/)  
[![MLflow](https://img.shields.io/badge/MLflow-3.x-lightgrey?logo=mlflow)](https://mlflow.org/)  
[![Kafka](https://img.shields.io/badge/Kafka-3.6.1-ff6600?logo=apache-kafka)](https://kafka.apache.org/)  
[![Docker](https://img.shields.io/badge/Docker-24.0-blue?logo=docker)](https://www.docker.com/)  
[![MinIO](https://img.shields.io/badge/MinIO-RE/OS-00a2ff?logo=minio)](https://min.io/)  
[![Postgres](https://img.shields.io/badge/Postgres-15.0-336791?logo=postgresql)](https://www.postgresql.org/)  
[![Redis](https://img.shields.io/badge/Redis-7.x-cc0000?logo=redis)](https://redis.io/)

---

</div>

## üìã Descripci√≥n general

**Autor:** Jorge √Ångel Manzanares Cort√©s  
**Proyecto:** Build a Fraud Detection AI from Scratch ‚Äî adaptaci√≥n y modernizaci√≥n de un tutorial de CodeWithYu.  
**Origen / Tutorial base:** https://www.youtube.com/watch?v=BY26sqZLi3k

Resumen: este repositorio contiene mi versi√≥n actualizada y compatible con stacks modernos (Airflow 3.x, Spark 4.0.1, MLflow 3.x, Kafka ajustado a 3.6.1). El objetivo es un pipeline E2E reproducible que genera datos sint√©ticos de transacciones, los inyecta en Kafka, orquesta pipelines con Airflow para entrenamiento y registro en MLflow (artefactos en MinIO), y finalmente realiza inferencia en streaming con Spark, publicando alertas de fraude de vuelta a Kafka.

---

## üìå Cambios principales realizados (migraci√≥n y compatibilidad)

- **Airflow ‚Üí 3.x**
  - El frontend y la organizaci√≥n interna de clases/funciones cambi√≥. Actualic√© DAGs, operadores y hooks a las nuevas rutas y APIs.
  - Ajustes en configuraciones de autenticaci√≥n y en la inicializaci√≥n del metastore.
- **Spark ‚Üí 4.0.1**
  - Spark 4 requiere compatibilizaciones con ciertos conectores; **no** es compatible con Kafka-clients 4.x, por lo que opt√© por **kafka-clients 3.6.1** y adapt√© dependencias.
- **MLflow ‚Üí 3.x**
  - Nueva capa de permisos/seguridad. Fue necesario crear una nueva `env` (variables/roles) y adaptar la configuraci√≥n del servidor MLflow para aceptar hosts y credenciales correctamente.
- **Seguridad en configs**
  - Elimin√© variables secretas del `config.yaml` y mov√≠ credenciales sensibles a `.env` o a secretos del orquestador (Docker secrets / Vault recomendado).

---

## üß© Contenedores (descripci√≥n funcional)

Lista de contenedores orquestados (ej. `docker-compose`):

- `src-inference-1`: Conector de inferencia (Spark structured streaming + UDFs para predicci√≥n en tiempo real).  
- `src-airflow-worker-1`, `src-airflow-worker-2`: Workers de ejecuci√≥n (Celery / CeleryExecutor).  
- `src-flower-1`: Flower ‚Äî monitor de tareas Celery.  
- `src-airflow-triggerer-1`: Triggerer de Airflow (tareas diferidas).  
- `src-airflow-scheduler-1`: Scheduler de Airflow.  
- `src-airflow-apiserver-1`: API server de Airflow.  
- `src-airflow-dag-processor-1`: Procesador de DAGs.  
- `mlflow-server`: Servidor MLflow (tracking, registry), con artefact store apuntando a MinIO.  
- `src-airflow-init-1`: Inicializaci√≥n de DB y recursos de Airflow.  
- `mc`: MinIO Client (CLI) para gestionar buckets/artefactos.  
- `src-postgres-1`: PostgreSQL (backend/metastore).  
- `src-redis-1`: Redis (broker para Celery / cach√©).  
- `src-producer-1`, `src-producer-2`: Producers que generan transacciones sint√©ticas y las publican a Kafka.  
- `minio`: Servidor de objetos (artefactos de MLflow, datos, modelos).

---

## üßæ Flujo de datos (alto nivel)

1. **Producers** generan transacciones sint√©ticas ‚Üí publican a **Kafka** (topic: `transactions`).  
2. **Airflow** orquesta DAGs que consumen desde Kafka / ETL / entrenamiento: prepara datasets, ejecuta aprendizaje, registra runs y modelos en **MLflow**; artefactos y modelos almacenados en **MinIO**.  
3. **Inference container** (Spark streaming) lee topic `transactions`, procesa y calcula predicciones en tiempo real, y publica eventos de alerta a `fraud_predictions` (otro topic en Kafka).  
4. Monitoreo: Flower (tareas), logs centralizados y MLflow/LangSmith (o similar) para trazabilidad de experiments.

---

## üî¨ Generaci√≥n de transacciones sint√©ticas (resumen de la l√≥gica)

Las transacciones se generan con reglas estoc√°sticas para simular patrones reales y fraude:

- Campos por transacci√≥n: `transaction_id`, `user_id`, `amount`, `currency`, `merchant`, `timestamp`, `location`, `is_fraud`.
- **Tipos de fraude simulados (reglas heur√≠sticas):**
  - **Account takeover:** usuarios comprometidos (`compromised_users`) con transacciones grandes (>500) tienen probabilidad de fraude; monto y merchant se alteran.  
  - **Card testing:** m√∫ltiples micropagos peque√±os (<2.0 USD) con patr√≥n r√°pido; probabilidad condicionada al `user_id`.  
  - **Merchant collusion:** merchants de alto riesgo (`high_risk_merchants`) que realizan transacciones sospechosas por montos altos.  
  - **Anomal√≠as geogr√°ficas:** transacciones desde pa√≠ses at√≠picos para el usuario (`CN`, `RU`, `GB`) en ocasiones espec√≠ficas.  
  - **Fraude aleatorio de base:** tasa baja de fraude ‚Äúbaseline‚Äù para ruido realista (‚âà0.1‚Äì0.3%).  
- **Control de tasa:** se aplica una l√≥gica adicional para mantener la tasa final de fraude entre ~1‚Äì2%.  
- **Validaci√≥n:** cada transacci√≥n pasa por una validaci√≥n de esquema antes de ser publicada.

> Nota: la generaci√≥n est√° pensada para crear un balance realista entre transacciones leg√≠timas y fraudulentas para entrenar y evaluar modelos.

---

## ‚úÖ Esquema de eventos (requisitos y validaciones)

En vez de c√≥digo, aqu√≠ tienes el **esquema resumido** (campo ‚Üí tipo ‚Üí restricciones):

- `transaction_id` ‚Üí string, identificador √∫nico (UUID).  
- `user_id` ‚Üí entero, rango t√≠pico 1000‚Äì9999 (o ID consistente).  
- `amount` ‚Üí n√∫mero decimal, m√≠nimo 0.01, m√°ximo ~10000.  
- `currency` ‚Üí string, ISO-3 (ej. `USD`).  
- `merchant` ‚Üí string.  
- `timestamp` ‚Üí datetime ISO 8601 (UTC preferible).  
- `location` ‚Üí string, ISO-2 pa√≠s (ej. `US`, `MX`).  
- `is_fraud` ‚Üí entero binario (0 o 1).  

Campos obligatorios para publicaci√≥n: `transaction_id`, `user_id`, `amount`, `currency`, `timestamp`, `is_fraud`. El resto puede ser opcional pero recomendado.

---

## üß† Feature engineering y entrenamiento (resumen metodol√≥gico)

- **Feature engineering (batch):**
  - Variables temporales: hora del d√≠a, d√≠a del mes, indicador noche/fin de semana.  
  - Ratios y agregados hist√≥ricos (rolling averages, tiempo desde √∫ltima transacci√≥n) ‚Äî cuando hay historial.  
  - Flags de merchant de alto riesgo, relaciones `amount / rolling_avg`.  
- **Pipeline ML (sklearn-style):**
  - Preprocesado de num√©ricas y categ√≥ricas (imputaci√≥n, encoding).  
  - Rebalanceo con **SMOTE** para mitigar el desbalance de clases.  
  - B√∫squeda de hiperpar√°metros con **RandomizedSearchCV** (o RandomGridSearchCV en tu implementaci√≥n).  
  - Modelo final: clasificadores tradicionales (ej. RandomForest / XGBoost ‚Äî seg√∫n experimentos).  
- **Resultados reportados (tus runs):**
  - **Precisi√≥n (precision):** 0.88  
  - **Recall:** 0.40  
  - M√©trica de decisi√≥n: se prioriz√≥ **precision** para minimizar falsos positivos en ambiente de producci√≥n; recall se ajusta en inferencia v√≠a umbral.

---

## üöÄ Inferencia en streaming (arquitectura y decisiones)

- **Motor:** Spark Structured Streaming (Spark 4.0.1).  
- **Lectura:** `readStream` desde Kafka (`transactions`), `startingOffsets=latest`.  
- **Parsing:** JSON ‚Üí esquema estructurado (tipos definidos para cada campo).  
- **Feature enrichment:** crear columnas temporales, indicadores (is_night, is_weekend), ratios y flags de riesgo.  
- **Modelo en producci√≥n:** modelo entrenado serializado (joblib) cargado por el proceso de Spark y **broadcasted** (para evitar re-env√≠o en cada task).  
- **Predicci√≥n:** UDF vectorizada (Pandas UDF) que recibe batches y retorna predicci√≥n binaria.  
  - Umbral de clasificaci√≥n sugerido: **0.70** (ajustable seg√∫n trade-off precision/recall).  
- **Salida:** solo predicciones de fraude de alta confianza se publican a `fraud_predictions` (Kafka), con checkpointing (por ejemplo `checkpoints/checkpoint`) para tolerancia a fallos.  
- **Observabilidad:** logs estructurados (INFO/ERROR) y monitoreo de latencia en el pipeline.

---

## üîß Problemas encontrados y soluciones (resumen pr√°ctico)

- **MLflow: Rechazo por encabezado Host / seguridad**
  - Causa: nueva pol√≠tica de validaci√≥n de Host y seguridad en MLflow 3.x.  
  - Soluci√≥n: crear una nueva env / variable `MLFLOW_SERVER_ALLOWED_HOSTS` adecuada y corregir la configuraci√≥n del server (host/puerto) y reverse-proxy si aplica.
- **Airflow: rutas y frontend**
  - Causa: reestructuraci√≥n de m√≥dulos y cambios en frontend.  
  - Soluci√≥n: actualizar imports, operadores y adaptadores; revisar breaking changes de Airflow 3.x.
- **Spark ‚Äî compatibilidad con Kafka-client**
  - Problema: Spark 4.0.1 no compatible con kafka-clients 4.x en mi stack.  
  - Soluci√≥n: usar **kafka-clients 3.6.1**, fijar versiones de jars y adaptar `spark.jars.packages` y dependencias.
- **Seguridad de configuraci√≥n**
  - Problema: secretos en `config.yaml`.  
  - Soluci√≥n: remover secretos del `config.yaml`, usar `.env`, Docker secrets o un secret manager.
- **Validaci√≥n de esquema**
  - Implementar validaci√≥n preventiva para evitar mensajes malformados en Kafka.

---

## üì¶ Reproducci√≥n (gu√≠a r√°pida, sin comandos)

1. Preparar `.env` con variables sensibles (KAFKA creds, MLflow credentials, MinIO keys).  
2. Levantar infra: Postgres, Redis, MinIO, Kafka, Zookeeper (si aplica), MLflow, Airflow via containers.  
3. Inicializar metastore de Airflow (migraciones) y crear buckets en MinIO.  
4. Ejecutar producers para empezar a enviar transacciones a Kafka.  
5. Ejecutar DAGs de Airflow para ETL / entrenamiento. Ver runs en MLflow.  
6. Levantar container de inferencia (Spark) para leer stream y generar `fraud_predictions`.

> Nota: Ajustes de red / hosts / puertos y configuraci√≥n de SASL/SCRAM o SSL en Kafka son cr√≠ticos ‚Äî revisa variables en `.env` y `config.yaml`.

---

## üìà Monitoring & MLOps

- **Tracking:** MLflow Tracking + Registry para versiones de modelo.  
- **Artefactos:** MinIO como object store para artefactos y modelos.  
- **Orquestaci√≥n:** Airflow 3.x para pipelines programados y DAGs de entrenamiento.  
- **Observabilidad:** Flower para Celery; logs estructurados; sugerido: Prometheus + Grafana para m√©tricas de latencia y errores.  
- **Trazabilidad:** incluir run-id de MLflow en metadatos de inferencia para correlaci√≥n.

---

## üõ†Ô∏è Recomendaciones y siguientes pasos

- A√±adir tests end-to-end (simulaci√≥n de producers ‚Üí Kafka ‚Üí Airflow ‚Üí MLflow ‚Üí Inference) en CI.  
- Implementar retraining autom√°tico (drift detection) traducido en DAGs de Airflow.  
- Mejorar el recall del modelo explorando ensembles y features agregadas hist√≥ricamente (ventanas temporales).  
- Habilitar m√©tricas de modelo en producci√≥n (drift, AUC over time, tasa de falsos positivos por segmento).
- **PASO SIGUIENTE: Implementar un pipeline CI/CD usando EKS y Kubernetes**

---

## üßæ Documentaci√≥n & archivos importantes (qu√© revisar)

- `docker-compose.yml` / orquestador: definici√≥n de servicios y redes.  
- `config.yaml` (sin secretos): plantillas de configuraci√≥n.  
- `.env.example`: variables necesarias para levantar el entorno.  
- `dags/`: DAGs de Airflow (ETL / train / register).  
- `models/` / `artifacts/`: lugar donde MLflow persiste los modelos (referenciados a MinIO).  
- `producers/` y `inference/`: scripts de generaci√≥n y de inferencia (Spark).

---

## üìò Cr√©ditos y licencia

Basado en el tutorial de CodeWithYu (video referenciado arriba). Esta versi√≥n contiene **mis adaptaciones y mejoras** para compatibilidad con versiones modernas de las herramientas y cambios en seguridad/infraestructura.

---

## üßë‚Äçüíª Autor & repositorio

**Jorge √Ångel Manzanares Cort√©s**  
Repositorio: `MLOPS-project-Credit-Card-Fraud-Detection-v2`  
üåê GitHub: https://github.com/takenking9879

---
